---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
```


# Simulations

We have seen how R can interact with common distributions. However, we sometimes
require distributions that are not part of the family of common ones, but can
be generated from it. Although it is sometimes possible to compute expectations
with respect to these distributions analytically, it will often be much simpler
to simply use software simulatinos to compute an approximate numerical quantity.

# The lognormal distribution

We have derived the p.d.f. of the log normal distribution in class. What about
its expectation? We could attempt to integrate the p.d.f., but that is difficult.
Let us instead simply generate a large random sample of log-normal variates, and
average them. By the law of large numbers, this should be close to the true expected
value.

Log-normal random variables can be generated by generating normal variates and
taking the exponential.
```{r}
x = rnorm(n=10000, mean=0, sd=1)
y = exp(x)

mean(y)
```

As we mentioned earlier in the course, the kernel density estimator can be
viewed as an attempt to estimate the density of the variable. We can
use this to obtain a graphical estimate of the density. We see that
in this case, we obtain an estimate that is close to the true density.

```{r}
# compute theoretical density using the dlnorm function
x.grid = seq(0, 20, 0.1)
y.theoretical = dlnorm(x.grid)

ggplot() +
  geom_density(aes(x = y)) +
  geom_line(aes(x = x.grid, y = y.theoretical), color='red') +
  xlim(0, 20)
```


# A more complex example

To understand the distribution of a simulated quantity, it can be useful to
plot an estimate of the cumulative distribution function, the empirical
distribution function or ECDF. For example, let us consider the following
problem:

Suppose that we have an industrial machine that requires power to work.
To supply this power, we have designed a power supply system with
4 independent components, that are partially redundant: the power supply
will work as long as at least 2 of the 4 components are working. Suppose
that the MTTF (mean time to failure) of each component is 100 hours.
What is the MTTF of the power supply?

In this problem, let us suppose that time to failure of each component
is exponential with parameter 1 / 100 (recall that the parameter is the
inverse of the mean).

Let us simulate the failure time of the power supply.

We first define a *function* that computes the time to failure
of the power supply. The power supply fails when the second component
fails, that is, at the second smallest time.
```{r}
power.ttf = function(ttfs) {
  sort(ttfs)[2]
}
```

Now we generate random failure times for each individual components,
and compute the power supply time to failure for each replication.
We then compute the average value.
```{r}
t = as_tibble(matrix(rexp(10000, rate=1/100), ncol=4))

ttf = t %>%
  rowwise() %>%
  mutate(ttf = power.ttf(c(V1, V2, V3, V4)))

mean(ttf$ttf)
```

# Empirical cumulative distribution functions

Suppose that instead of simply understanding the mean, we wish to
understand the probability of the power supply failing before a
given time, for all possible times. If we had access to the
distribution of the quantity, this would simply be the cumulative
distribution function of the time to failure.

In our case, we may estimate the cumulative distribution function
by the empirical cumulative distribution function. This function
describes the proportion of samples less than a given value.

```{r}
ggplot(data=ttf) + stat_ecdf(aes(x = ttf))
```

# Another example: Risk

Risk is a board game with some random component in dice rolls. Suppose we
wish to understand the distribution of the outcomes of a battle, and
in particular the chance of winning and the number of remaining units.

In order to understand the possible outcomes better, we simply repeat
the process 1000 times, simulating all the dice rolls.

```{r}
risk.simulate = function(n.a, n.d) {
  while ((n.a > 0) & (n.d > 0)) {
    rolls.a = sample.int(6, size=min(3, n.a), replace=T)
    rolls.d = sample.int(6, size=min(2, n.d), replace=T)
  
    rolls.count = min(length(rolls.a), length(rolls.d))
  
    loss.d = sum(sort(rolls.a, decreasing = FALSE)[1:rolls.count] >
        sort(rolls.d, decreasing = FALSE)[1:rolls.count])
  
    n.a = n.a - (rolls.count - loss.d)
    n.d = n.d - loss.d
  }
  
  c(n.a, n.d)
}
```

```{r}
results = replicate(1000, risk.simulate(4, 2))
results = tibble(n.a=results[1,], n.d=results[2,])
```

```{r}
ggplot(data=results) + geom_histogram(aes(x=n.a, y=..density..), binwidth = 1)
```

We see that in this case, the distribution of the remaining number of attackers
is complex: it is more likely to have 4 attackers remaining than 3.


